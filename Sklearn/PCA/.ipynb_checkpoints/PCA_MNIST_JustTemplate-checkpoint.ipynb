{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> PCA + Logistic Regression (MNIST) </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
    "<br>\n",
    "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST database of handwritten digits is available on the following website: [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four Files are available on this site:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[train-images-idx3-ubyte.gz:  training set images (9912422 bytes)](http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz) \n",
    "<br>\n",
    "[train-labels-idx1-ubyte.gz:  training set labels (28881 bytes)](http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz)\n",
    "<br>\n",
    "[t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes)](http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz) \n",
    "<br>\n",
    "[t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)](http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include Table here of dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "# Suppress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Used for Loading MNIST\n",
    "from struct import unpack\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the data via command line (you can see this on the youtube video) or you can get them from the website or my github. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>If you cant unzip the file, you can try gzip or download it from [my github](https://github.com/mGalarnyk/Python_Tutorials/tree/master/Sklearn/Logistic_Regression/data)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decompress gzipped file\n",
    "# !info gzip\n",
    "# !gzip -d data/*.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadmnist(imagefile, labelfile):\n",
    "\n",
    "    # Open the images with gzip in read binary mode\n",
    "    images = open(imagefile, 'rb')\n",
    "    labels = open(labelfile, 'rb')\n",
    "\n",
    "    # Get metadata for images\n",
    "    images.read(4)  # skip the magic_number\n",
    "    number_of_images = images.read(4)\n",
    "    number_of_images = unpack('>I', number_of_images)[0]\n",
    "    rows = images.read(4)\n",
    "    rows = unpack('>I', rows)[0]\n",
    "    cols = images.read(4)\n",
    "    cols = unpack('>I', cols)[0]\n",
    "\n",
    "    # Get metadata for labels\n",
    "    labels.read(4)\n",
    "    N = labels.read(4)\n",
    "    N = unpack('>I', N)[0]\n",
    "\n",
    "    # Get data\n",
    "    x = np.zeros((N, rows*cols), dtype=np.uint8)  # Initialize numpy array\n",
    "    y = np.zeros(N, dtype=np.uint8)  # Initialize numpy array\n",
    "    for i in range(N):\n",
    "        for j in range(rows*cols):\n",
    "            tmp_pixel = images.read(1)  # Just a single byte\n",
    "            tmp_pixel = unpack('>B', tmp_pixel)[0]\n",
    "            x[i][j] = tmp_pixel\n",
    "        tmp_label = labels.read(1)\n",
    "        y[i] = unpack('>B', tmp_label)[0]\n",
    "\n",
    "    images.close()\n",
    "    labels.close()\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img, train_lbl = loadmnist('data/train-images-idx3-ubyte'\n",
    "                                 , 'data/train-labels-idx1-ubyte')\n",
    "test_img, test_lbl = loadmnist('data/t10k-images-idx3-ubyte'\n",
    "                               , 'data/t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_lbl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(test_lbl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing Training Digits and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAEKCAYAAACFeUV9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQyAAAAAAAIACYAgEAAAAAABQAP8fMSvuV4xJk/IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fdbc090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(train_img[0:5], train_lbl[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# This is how the computer sees the number 5\n",
    "print(train_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u,s,v = np.linalg.svd(train_img.T, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "        -0.27912624,  0.11150906],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.45716139,  0.44563819],\n",
       "       [ 0.        ,  0.        , -0.        , ...,  0.        ,\n",
       "        -0.23366141,  0.57551898],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Number of Principal Components with 95% of Explained Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe try to mimic the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=784, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(train_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us an object we can use to transform our data by calling transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pca.transform(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3428502.5747802043"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot = sum(pca.explained_variance_)\n",
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.7046643597139379, 7.0959240590944637, 6.1690887623681423, 5.389419486553364, 4.8687970234748263]\n"
     ]
    }
   ],
   "source": [
    "var_exp = [(i/tot)*100 for i in sorted(pca.explained_variance_, reverse=True)] \n",
    "print(var_exp[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eig_vals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b56a24969377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvar_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meig_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Individual explained variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eig_vals' is not defined"
     ]
    }
   ],
   "source": [
    "var_exp = [(i/tot)*100 for i in sorted(eig_vals, reverse=True)] # Individual explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cum_var_exp = np.cumsum(var_exp) # Cumulative explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(cum_var_exp > 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.axhline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OUT THE EXPLAINED VARIANCES SUPERIMPOSED \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(0, 784), var_exp, alpha=0.3333, align='center', label='individual explained variance', color = 'g')\n",
    "plt.step(range(0, 784), cum_var_exp, where='mid',label='cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.axhline(y = 95, color='k', linestyle='--', label = '95% Explained Variance')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=153)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcStuff = pca.transform(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stats.stackexchange.com/questions/229092/how-to-reverse-pca-and-reconstruct-original-variables-from-several-principal-com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalised [0,255] as integer\n",
    "pd.DataFrame(data = (255*(pcStuff - np.max(pcStuff))/-np.ptp(pcStuff)).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression on Entire Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Logistic Regression Sklearn Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) <br>\n",
    "One thing I like to mention is the importance of parameter tuning. While it may not have mattered much for the toy digits dataset, it can make a major difference on larger and more complex datasets you have. <b>Please see the parameter: solver</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1: </b> Import the model you want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sklearn, all machine learning models are implemented as Python classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2:</b> Make an instance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all parameters not specified are set to their defaults\n",
    "# default solver is incredibly slow thats why we change it\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3:</b> Training the model on the data, storing the information learned from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is learning the relationship between x (digits) and y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr.fit(train_img, train_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 4:</b> Predict the labels of new data (new images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses the information the model learned during the model training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a NumPy Array\n",
    "# Predict for One Observation (image)\n",
    "logisticRegr.predict(test_img[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for Multiple Observations (images) at Once\n",
    "logisticRegr.predict(test_img[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy (fraction of correct predictions): correct predictions / total number of data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, how the model performs on new data (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = logisticRegr.score(test_img, test_lbl)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: Seaborn needs to be installed for this portion </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !conda install seaborn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "predictions = logisticRegr.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(test_lbl, predictions)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {:.3f}'.format(score) \n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Misclassified images with Predicted Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "misclassifiedIndexes = []\n",
    "for label, predict in zip(test_lbl, predictions):\n",
    "    if label != predict: \n",
    "        misclassifiedIndexes.append(index)\n",
    "    index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for plotIndex, badIndex in enumerate(misclassifiedIndexes[0:5]):\n",
    "    plt.subplot(1, 5, plotIndex + 1)\n",
    "    plt.imshow(np.reshape(test_img[badIndex], (28,28)), cmap=plt.cm.gray)\n",
    "    plt.title('Predicted: {}, Actual: {}'.format(predictions[badIndex], test_lbl[badIndex]), fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Performance Based on Training Set Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regr = LogisticRegression(solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (24,8));\n",
    "plt.tight_layout()\n",
    "\n",
    "for plotIndex, sample_size in enumerate([100, 1000, 60000]):\n",
    "    X_train = train_img[:sample_size].reshape(sample_size, 784)\n",
    "    y_train = train_lbl[:sample_size]\n",
    "    regr.fit(X_train, y_train)\n",
    "    predicted = regr.predict(test_img)\n",
    "    cm = metrics.confusion_matrix(test_lbl, predicted)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r', ax = axes[plotIndex], cbar = False);\n",
    "    accuracyString = '{:g} Training Samples Score: {:.3f}'.format(sample_size, regr.score(test_img, test_lbl)) \n",
    "    axes[plotIndex].set_title(accuracyString, size = 25);\n",
    "\n",
    "axes[0].set_ylabel('Actual label', fontsize = 30);\n",
    "axes[1].set_xlabel('Predicted label', fontsize = 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
